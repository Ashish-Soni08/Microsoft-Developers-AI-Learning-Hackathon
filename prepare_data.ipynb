{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "import fitz\n",
    "\n",
    "from rich import print\n",
    "from rich.pretty import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLIT THE MAIN PDF BY EACH SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_pdf(page_numbers: List[int], new_pdf_name: str, pdf_path: str = \"data/raw/Master_Thesis_Aidana_Rakhatbekova.pdf\") -> None:\n",
    "    \"\"\"\n",
    "    Partitions a PDF by selecting specific pages and saves the result to a new PDF file.\n",
    "\n",
    "    Parameters:\n",
    "        page_numbers (List[int]): A list of page numbers to select from the original PDF.\n",
    "        new_pdf_name (str): The file path where the new PDF will be saved.\n",
    "        pdf_path (str, optional): The file path of the original PDF. Defaults to \"data/raw/Master_Thesis_Aidana_Rakhatbekova.pdf\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    doc.select(page_numbers)\n",
    "    doc.save(new_pdf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([1, 2, 3, 4, 5], \"data/processed/Introduction.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], \"data/processed/State_of_the_Art.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([18, 19, 20, 21], \"data/processed/Theoretical_Framework.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([21, 22, 23, 24, 25, 26], \"data/processed/Methodology.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([27, 28, 29, 30, \n",
    "               31, 32, 33, 34, 35, \n",
    "               36, 37, 38, 39, 40,\n",
    "               41, 42, 43, 44, 45, \n",
    "               46, 47, 48, 49, 50, \n",
    "               51, 52, 53, 54, 55, \n",
    "               56, 57, 58, 59], \"data/processed/Analysis_and_Presentation_of_Findings.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([59, 60, 61, 62, 63], \"data/processed/Conclusion.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([64, 65, 66, 67, 68, 69, 70], \"data/processed/References.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([71, 72], \"data/processed/Appendix_A.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_pdf([75], \"data/processed/Appendix_B.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLamaParse to Parse PDF to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import (AZURE_OPENAI_ENDPOINT,\n",
    "                       AZURE_OPENAI_API_KEY,\n",
    "                       AZURE_OPENAI_API_VERSION,\n",
    "                       DB_CONNECTION,\n",
    "                       EMBEDDING_MODEL,\n",
    "                       LLM,\n",
    "                       LLAMAPARSE_API_KEY,\n",
    "                       LANGCHAIN_URL,\n",
    "                       LANGCHAIN_API_KEY,\n",
    "                       LANGCHAIN_PROJECT    \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = LANGCHAIN_URL\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "parser = LlamaParse(\n",
    "api_key=LLAMAPARSE_API_KEY,\n",
    "result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "verbose=True,\n",
    "language=\"en\")\n",
    "\n",
    "file_extractor = {\".pdf\": parser}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_markdown_from_pdf(api_key: str = LLAMAPARSE_API_KEY, folder_path: str = \"data/processed\"):\n",
    "    from llama_parse import LlamaParse\n",
    "    from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "    parser = LlamaParse(\n",
    "    api_key=LLAMAPARSE_API_KEY,\n",
    "    result_type=\"markdown\",  # \"markdown\" and \"text\" are available\n",
    "    verbose=True,\n",
    "    language=\"en\")\n",
    "\n",
    "    file_extractor = {\".pdf\": parser}\n",
    "    \n",
    "    documents = SimpleDirectoryReader(\"./data\", file_extractor=file_extractor).load_data()\n",
    "\n",
    "    print(\"Total Number of Documents parsed ->\", len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "\n",
    "markdown_parser = MarkdownNodeParser()\n",
    "nodes = markdown_parser.get_nodes_from_documents(documents, include_metadata=True, include_prev_next_rel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = [\"INTRODUCTION\",\n",
    "            \"STATE OF THE ART\",\n",
    "            \"THEORETICAL FRAMEWORK\",\n",
    "            \"METHODOLOGY\",\n",
    "            \"ANALYSIS AND PRESENTATION OF FINDINGS\",\n",
    "            \"CONCLUSION\",\n",
    "            \"APPENDIX A\",\n",
    "            \"APPENDIX B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A futuristic, beautiful brain with intricate and glowing neural pathways, set against a sleek, high-tech background. The brain should look advanced and ethereal, with elements of cyberpunk and bioluminescence. Below the brain, the words 'The Decolonized Mind' are written in elegant, modern typography, seamlessly integrated into the design.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(            \n",
    "        temperature = 0.2,\n",
    "        openai_api_version = AZURE_OPENAI_API_VERSION,\n",
    "        azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "        openai_api_key = AZURE_OPENAI_API_KEY,         \n",
    "        model_name = LLM\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = HumanMessage(\n",
    "    content=\"Translate this sentence from English to Hindi. I love programming.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='मुझे प्रोग्रामिंग करना बहुत पसंद है।', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 19, 'total_tokens': 55}, 'model_name': 'gpt-4-32k:swedencentral', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-9c1af7b5-963e-44af-9664-6abbfc444336-0', usage_metadata={'input_tokens': 19, 'output_tokens': 36, 'total_tokens': 55})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "ai_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def generate_embeddings(text: str):\n",
    "    '''\n",
    "    Generate embeddings from string of text using the deployed Azure OpenAI API embeddings model.\n",
    "    This will be used to vectorize document data and incoming user messages for a similarity search with\n",
    "    the vector index.\n",
    "    '''\n",
    "    response = ai_client.embeddings.create(input=text, model=EMBEDDING_MODEL)\n",
    "    embeddings = response.data[0].embedding\n",
    "    time.sleep(0.5) # rest period to avoid rate limiting on AOAI\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate embeddings generation using a test string\n",
    "# test = \"hello, world\"\n",
    "# print(generate_embeddings(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import AzureCosmosDBVectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = AzureCosmosDBVectorSearch.from_connection_string(\n",
    "    connection_string = DB_CONNECTION,\n",
    "    namespace = \"test\",\n",
    "    embedding = embedding_model,\n",
    "    index_name = \"test_index\",\n",
    "    embedding_key = \"content_vector\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2531/1043822493.py:1: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  client = pymongo.MongoClient(DB_CONNECTION)\n"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient(DB_CONNECTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.thesis_vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['c.pdf-ag-cosmos-mongodb.mongocluster.cosmos.azure.com:10260'], document_class=dict, tz_aware=False, connect=True, tls=True, authmechanism='SCRAM-SHA-256', retrywrites=False, maxidletimems=120000), 'thesis_vectordb')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsoft-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
